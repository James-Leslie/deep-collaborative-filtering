{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens 1m Collaborative Genre Tagging\n",
    "**To do**:\n",
    "  - try out [this implementation](https://www.onceupondata.com/2019/02/10/nn-collaborative-filtering/) of baseline features. \n",
    "  - create object classes for models\n",
    "  - implement TF 2.0 data classes\n",
    "  - [paperswithcode link](https://paperswithcode.com/sota/collaborative-filtering-on-movielens-100k)\n",
    "  - [ML 100k state of the art paper](https://arxiv.org/pdf/1706.02263v2.pdf) (RMSE=0.905): details their evaluation method\n",
    "  \n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/James-Leslie/deep-collaborative-filtering/blob/master/tf-movielens10m.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Add, Dense, Concatenate, Dropout, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load rating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'https://raw.githubusercontent.com/James-Leslie/deep-collaborative-filtering/master/data/ml-100k/'  # access from anywhere\n",
    "# path = 'data/ml-100k/'  # if the files are local\n",
    "path = 'data/ml-10M100K/'  # ML-1m file\n",
    "\n",
    "all_files = glob.glob(os.path.join(path, \"ratings*.csv\"))\n",
    "df = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>69587</td>\n",
       "      <td>1005</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>47904</td>\n",
       "      <td>193</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>26906</td>\n",
       "      <td>3097</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31241</td>\n",
       "      <td>559</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>69402</td>\n",
       "      <td>2541</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0   69587     1005     2.0\n",
       "1   47904      193     4.0\n",
       "2   26906     3097     3.5\n",
       "3   31241      559     1.0\n",
       "4   69402     2541     4.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000054, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 69878\n",
      "Number of items: 10677\n",
      "Min item rating: 0.5\n",
      "Max item rating: 5.0\n",
      "Mean item rating: 3.512421932921562\n"
     ]
    }
   ],
   "source": [
    "print('Number of users:', df.userId.nunique())\n",
    "print('Number of items:', df.movieId.nunique())\n",
    "print(\"Min item rating:\", df.rating.min())\n",
    "print(\"Max item rating:\", df.rating.max())\n",
    "print(\"Mean item rating:\", df.rating.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load movie metadata\n",
    "  - remove 10% as holdout test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Boomerang (1992)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Net, The (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Dumb &amp; Dumber (1994)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Outbreak (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Stargate (1994)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                 title  Action  Adventure  Animation  Children  \\\n",
       "0        0      Boomerang (1992)       0          0          0         0   \n",
       "1        1       Net, The (1995)       1          0          0         0   \n",
       "2        2  Dumb & Dumber (1994)       0          0          0         0   \n",
       "3        3       Outbreak (1995)       1          0          0         0   \n",
       "4        4       Stargate (1994)       1          1          0         0   \n",
       "\n",
       "   Comedy  Crime  Documentary  Drama  Fantasy  Film-Noir  Horror  Musical  \\\n",
       "0       1      0            0      0        0          0       0        0   \n",
       "1       0      1            0      0        0          0       0        0   \n",
       "2       1      0            0      0        0          0       0        0   \n",
       "3       0      0            0      1        0          0       0        0   \n",
       "4       0      0            0      0        0          0       0        0   \n",
       "\n",
       "   Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0        1       0         0    0        0  \n",
       "1        0        0       0         1    0        0  \n",
       "2        0        0       0         0    0        0  \n",
       "3        0        0       1         1    0        0  \n",
       "4        0        0       1         0    0        0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(path+'movies.tsv', sep='\\t')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9609, 20), (1068, 20))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies, movies_holdout = train_test_split(movies, test_size=.1, random_state=42)\n",
    "movies.shape, movies_holdout.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Create baseline features\n",
    "For each user, calculate average user bias - the average difference between the user's rating and the movie's average rating:\n",
    "\n",
    "$$b_{u} = \\dfrac{\\sum_{j=1}^{n_u} (r_{uj} - \\mu_i)}{n_u}$$\n",
    "\n",
    "For each item, calculate the difference between its average rating and the average rating of all movies:\n",
    "\n",
    "$$b_{i} = \\dfrac{\\sum_{k=1}^{n_i} (r_{ki})}{n_i} - \\mu$$\n",
    "\n",
    "Then, for each interaction, calculate the combined bias:\n",
    "\n",
    "$$b_{ui} = \\dfrac{b_u + b_i}{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline(df, train_index, test_index):\n",
    "    \n",
    "    '''\n",
    "    Calculate baseline features from an explicit ratings dataset. Receives a dataframe\n",
    "    and returns train and test splits with added bias column and mean rating value.\n",
    "    User and item biases are calculated as average difference from global mean rating.\n",
    "    Baseline factors are only calculated from training observations, with users or\n",
    "    items that do not appear in train receiving the global average as default.\n",
    "    \n",
    "    Args:\n",
    "        df          : explicit ratings dataframe with columns userId, movieId and rating\n",
    "        train_index : train index splits taken from KFold.splits()\n",
    "        test_index  : test index splits taken from KFold.splits()\n",
    "        \n",
    "    Returns:\n",
    "        train, test : train/test splits of df, with added bias column\n",
    "        global_mean : average rating of all training observations\n",
    "    '''\n",
    "    \n",
    "    train = df.iloc[train_index]\n",
    "    test = df.iloc[test_index]\n",
    "    \n",
    "    # compute global mean\n",
    "    global_mean = train.rating.mean()\n",
    "\n",
    "    # compute average item ratings\n",
    "    item_averages = train.groupby(\n",
    "        'movieId'\n",
    "    ).agg(\n",
    "        {'rating':'mean'}\n",
    "    ).rename(\n",
    "        {'rating': 'item_avg'}, axis=1\n",
    "    ).reset_index()\n",
    "    \n",
    "    # add as column to train and test\n",
    "    train = pd.merge(train, item_averages, how='left', on='movieId')\n",
    "    test = pd.merge(test, item_averages, how='left', on='movieId').fillna(global_mean)\n",
    "    \n",
    "    # compute average user bias\n",
    "    train['user_bias'] = train['rating'] - train['item_avg']\n",
    "    \n",
    "    user_biases = train.groupby(\n",
    "        'userId'\n",
    "    ).agg(\n",
    "        {'user_bias':'mean'}\n",
    "    ).rename(\n",
    "        {'user_bias': 'user_avg'}, axis=1\n",
    "    ).reset_index()\n",
    "    \n",
    "    # add as column to train and test\n",
    "    train = pd.merge(train, user_biases, how='left', on='userId')\n",
    "    test = pd.merge(test, user_biases, how='left', on='userId').fillna(0.0)\n",
    "    \n",
    "    # interaction bias\n",
    "    train['bias'] = (train['user_avg'] + train['item_avg'] - global_mean)/2\n",
    "    test['bias'] = (test['user_avg'] + test['item_avg'] - global_mean)/2\n",
    "    \n",
    "    return train, test, global_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Genre model\n",
    "**To do**:\n",
    "  - Can we avoid re-training rating model on CV fold?\n",
    "  - Create a grid search function / class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_genre_model(n_items, n_users, mean_rating, n_latent, n_hidden_1, n_hidden_2, dropout_1=.25, dropout_2=.25):\n",
    "    \n",
    "    # item latent factors\n",
    "    item_in = Input(shape=[1])  # name='item'\n",
    "    item_em = Embedding(n_items, n_latent)(item_in)\n",
    "    item_vec = Flatten()(item_em)\n",
    "    \n",
    "    # user latent factors\n",
    "    user_in = Input(shape=[1])\n",
    "    user_em = Embedding(n_users, n_latent)(user_in)\n",
    "    user_vec = Flatten()(user_em)\n",
    "    \n",
    "    # user x item bias\n",
    "    bias = Input(shape=[1])\n",
    "    \n",
    "    # concatenate user and item vectors\n",
    "    conc = Concatenate()([item_vec, user_vec])\n",
    "    # hidden layer\n",
    "    hidden_1 = Dense(n_hidden_1)(conc)\n",
    "    leaky = LeakyReLU(alpha=.1)(hidden_1)\n",
    "    drop_1 = Dropout(dropout_1)(leaky)\n",
    "    \n",
    "    out = Dense(1)(drop_1)\n",
    "            \n",
    "    rating = tf.math.add(Add()([out, bias]), mean_rating)\n",
    "    \n",
    "    # create model and compile it\n",
    "    model = Model([user_in, item_in, bias], rating)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # model 2\n",
    "    hidden_2 = Dense(n_hidden_2, activation='relu')(item_vec)\n",
    "    drop_2 = Dropout(dropout_2)(hidden_2)\n",
    "    genre = Dense(1, activation='sigmoid')(drop_2)\n",
    "\n",
    "    # Create model and compile it\n",
    "    model2 = Model(item_in, genre)\n",
    "    # freeze the embedding layer\n",
    "    model2.layers[1].trainable = False\n",
    "    model2.compile(optimizer='adam', loss='binary_crossentropy' , metrics=['accuracy', 'AUC'])\n",
    "    \n",
    "    return model, model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-train model on full dataset, with best hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000043 samples, validate on 2000011 samples\n",
      "Epoch 1/8\n",
      "8000043/8000043 [==============================] - 690s 86us/sample - loss: 0.7245 - val_loss: 0.6933\n",
      "Epoch 2/8\n",
      "8000043/8000043 [==============================] - 692s 87us/sample - loss: 0.6784 - val_loss: 0.6723\n",
      "Epoch 3/8\n",
      "8000043/8000043 [==============================] - 702s 88us/sample - loss: 0.6562 - val_loss: 0.6630\n",
      "Epoch 4/8\n",
      "8000043/8000043 [==============================] - 688s 86us/sample - loss: 0.6399 - val_loss: 0.6534\n",
      "Epoch 5/8\n",
      "8000043/8000043 [==============================] - 686s 86us/sample - loss: 0.6258 - val_loss: 0.6468\n",
      "Epoch 6/8\n",
      "8000043/8000043 [==============================] - 688s 86us/sample - loss: 0.6143 - val_loss: 0.6424\n",
      "Epoch 7/8\n",
      "8000043/8000043 [==============================] - 693s 87us/sample - loss: 0.6042 - val_loss: 0.6391\n",
      "Epoch 8/8\n",
      "8000043/8000043 [==============================] - 717s 90us/sample - loss: 0.5953 - val_loss: 0.6357\n",
      "Train on 9609 samples\n",
      "Epoch 1/7\n",
      "9609/9609 [==============================] - 3s 269us/sample - loss: 0.5897 - accuracy: 0.6854 - AUC: 0.7515\n",
      "Epoch 2/7\n",
      "9609/9609 [==============================] - 2s 207us/sample - loss: 0.5637 - accuracy: 0.7082 - AUC: 0.7791\n",
      "Epoch 3/7\n",
      "9609/9609 [==============================] - 2s 206us/sample - loss: 0.5587 - accuracy: 0.7122 - AUC: 0.7837\n",
      "Epoch 4/7\n",
      "9609/9609 [==============================] - ETA: 0s - loss: 0.5555 - accuracy: 0.7123 - AUC: 0.78 - 2s 207us/sample - loss: 0.5553 - accuracy: 0.7128 - AUC: 0.7869\n",
      "Epoch 5/7\n",
      "9609/9609 [==============================] - 2s 206us/sample - loss: 0.5517 - accuracy: 0.7160 - AUC: 0.7903\n",
      "Epoch 6/7\n",
      "9609/9609 [==============================] - 2s 206us/sample - loss: 0.5486 - accuracy: 0.7196 - AUC: 0.7927\n",
      "Epoch 7/7\n",
      "9609/9609 [==============================] - 2s 202us/sample - loss: 0.5465 - accuracy: 0.7197 - AUC: 0.7943\n"
     ]
    }
   ],
   "source": [
    "# get baseline predictors for full dataset\n",
    "train, _, _ = get_baseline(df, df.index, df.index)\n",
    "\n",
    "# compile both models\n",
    "model1, model2 = compile_genre_model(\n",
    "    n_items = df.movieId.nunique(),\n",
    "    n_users = df.userId.nunique(),\n",
    "    mean_rating = df.rating.mean(), \n",
    "    n_latent=80,\n",
    "    n_hidden_1=75,\n",
    "    n_hidden_2=75\n",
    ")\n",
    "\n",
    "# train rating model\n",
    "ratings = model1.fit(\n",
    "    x=[train.userId.values, train.movieId.values, train.bias.values],\n",
    "    y=train.rating.values, \n",
    "    batch_size=1028,\n",
    "    epochs=8,\n",
    "    verbose=1,\n",
    "    validation_split=.2\n",
    ")\n",
    "\n",
    "# train genre model\n",
    "genres = model2.fit(\n",
    "    movies.movieId.values, movies.Drama.values,\n",
    "    batch_size=32, \n",
    "    epochs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test set\n",
    "**Best**: 70% with 80 : 75 | 75 hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.515918\n",
       "1    0.484082\n",
       "Name: Drama, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class proportions\n",
    "movies_holdout.Drama.value_counts()/len(movies_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = movies_holdout.movieId.values\n",
    "y_test = movies_holdout.Drama.values\n",
    "y_score = pd.DataFrame(model2.predict(X_test))\n",
    "y_pred = y_score.round().astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71       551\n",
      "           1       0.69      0.73      0.71       517\n",
      "\n",
      "    accuracy                           0.71      1068\n",
      "   macro avg       0.71      0.71      0.71      1068\n",
      "weighted avg       0.71      0.71      0.71      1068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>378</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  378  173\n",
       "1  140  377"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
