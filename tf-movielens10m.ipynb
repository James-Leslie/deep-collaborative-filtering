{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens 10M Collaborative Genre Tagging\n",
    "**To do**:\n",
    "  - try out [this implementation](https://www.onceupondata.com/2019/02/10/nn-collaborative-filtering/) of baseline features. \n",
    "  - create object classes for models\n",
    "  - implement TF 2.0 data classes\n",
    "  - [paperswithcode link](https://paperswithcode.com/sota/collaborative-filtering-on-movielens-100k)\n",
    "  - [ML 100k state of the art paper](https://arxiv.org/pdf/1706.02263v2.pdf) (RMSE=0.905): details their evaluation method\n",
    "  \n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/James-Leslie/deep-collaborative-filtering/blob/master/tf-movielens10m.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load rating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/ml-10M100K/'  # ML-10M files\n",
    "\n",
    "all_files = glob.glob(os.path.join(path, \"ratings*.csv\"))\n",
    "df = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       0        0       3\n",
       "1       1        1       3\n",
       "2       2        2       1\n",
       "3       3        3       2\n",
       "4       4        4       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943\n",
      "Number of items: 1682\n",
      "Min item rating: 1\n",
      "Max item rating: 5\n",
      "Mean item rating: 3.52986\n"
     ]
    }
   ],
   "source": [
    "print('Number of users:', df.userId.nunique())\n",
    "print('Number of items:', df.movieId.nunique())\n",
    "print(\"Min item rating:\", df.rating.min())\n",
    "print(\"Max item rating:\", df.rating.max())\n",
    "print(\"Mean item rating:\", df.rating.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load movie metadata\n",
    "  - remove 10% as holdout test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>link</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>233</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId              title  releaseDate  \\\n",
       "0       24   Toy Story (1995)  01-Jan-1995   \n",
       "1      147   GoldenEye (1995)  01-Jan-1995   \n",
       "2      233  Four Rooms (1995)  01-Jan-1995   \n",
       "3       47  Get Shorty (1995)  01-Jan-1995   \n",
       "4       75     Copycat (1995)  01-Jan-1995   \n",
       "\n",
       "                                                link  unknown  Action  \\\n",
       "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
       "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
       "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n",
       "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...        0       1   \n",
       "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)        0       0   \n",
       "\n",
       "   Adventure  Animation  Children's  Comedy  ...  Fantasy  Film-Noir  Horror  \\\n",
       "0          0          1           1       1  ...        0          0       0   \n",
       "1          1          0           0       0  ...        0          0       0   \n",
       "2          0          0           0       0  ...        0          0       0   \n",
       "3          0          0           0       1  ...        0          0       0   \n",
       "4          0          0           0       0  ...        0          0       0   \n",
       "\n",
       "   Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0        0        0       0         0    0        0  \n",
       "1        0        0        0       0         1    0        0  \n",
       "2        0        0        0       0         1    0        0  \n",
       "3        0        0        0       0         0    0        0  \n",
       "4        0        0        0       0         1    0        0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(path+'movies.csv')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies, movies_holdout = train_test_split(movies, test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Create baseline features\n",
    "For each user, calculate average user bias - the average difference between the user's rating and the movie's average rating:\n",
    "\n",
    "$$b_{u} = \\dfrac{\\sum_{j=1}^{n_u} (r_{uj} - \\mu_i)}{n_u}$$\n",
    "\n",
    "For each item, calculate the difference between its average rating and the average rating of all movies:\n",
    "\n",
    "$$b_{i} = \\dfrac{\\sum_{k=1}^{n_i} (r_{ki})}{n_i} - \\mu$$\n",
    "\n",
    "Then, for each interaction, calculate the combined bias:\n",
    "\n",
    "$$b_{ui} = \\dfrac{b_u + b_i}{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mget_baseline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Calculate baseline features from an explicit ratings dataset. Receives a dataframe\n",
       "and returns train and test splits with added bias column and mean rating value.\n",
       "User and item biases are calculated as average difference from global mean rating.\n",
       "Baseline factors are only calculated from training observations, with users or\n",
       "items that do not appear in train receiving the global average as default.\n",
       "\n",
       "Args:\n",
       "    df          : explicit ratings dataframe with columns userId, movieId and rating\n",
       "    train_index : train index splits taken from KFold.splits()\n",
       "    test_index  : test index splits taken from KFold.splits()\n",
       "    \n",
       "Returns:\n",
       "    train, test : train/test splits of df, with added bias column\n",
       "    global_mean : average rating of all training observations\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\jleslie\\documents\\deep-collaborative-filtering\\cgt.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from CGT import get_baseline\n",
    "?get_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# CGT model\n",
    "**To do**:\n",
    "  - Can we avoid re-training rating model on CV fold?\n",
    "  - Create a grid search function / class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mcompile_genre_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_items\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_users\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmean_rating\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_latent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_hidden_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_hidden_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mleaky_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdropout_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdropout_2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\jleslie\\documents\\deep-collaborative-filtering\\cgt.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from CGT import compile_genre_model\n",
    "?compile_genre_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-train model on full dataset, with best hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 2s 25us/sample - loss: 0.9035 - val_loss: 0.8593\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 2s 19us/sample - loss: 0.8515 - val_loss: 0.8498\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 2s 19us/sample - loss: 0.8295 - val_loss: 0.8422\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 1s 18us/sample - loss: 0.8079 - val_loss: 0.8384\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 1s 18us/sample - loss: 0.7850 - val_loss: 0.8339\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 1s 18us/sample - loss: 0.7623 - val_loss: 0.8300\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 1s 19us/sample - loss: 0.7388 - val_loss: 0.8276\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 1s 18us/sample - loss: 0.7172 - val_loss: 0.8317\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 2s 20us/sample - loss: 0.6979 - val_loss: 0.8292\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 1s 18us/sample - loss: 0.6790 - val_loss: 0.8403\n",
      "Train on 1210 samples, validate on 303 samples\n",
      "Epoch 1/6\n",
      "1210/1210 [==============================] - 1s 660us/sample - loss: 0.6890 - accuracy: 0.5421 - AUC: 0.5100 - val_loss: 0.6750 - val_accuracy: 0.5908 - val_AUC: 0.6577\n",
      "Epoch 2/6\n",
      "1210/1210 [==============================] - 0s 44us/sample - loss: 0.6681 - accuracy: 0.5917 - AUC: 0.6598 - val_loss: 0.6464 - val_accuracy: 0.6370 - val_AUC: 0.7064\n",
      "Epoch 3/6\n",
      "1210/1210 [==============================] - 0s 44us/sample - loss: 0.6519 - accuracy: 0.5959 - AUC: 0.6643 - val_loss: 0.6208 - val_accuracy: 0.6271 - val_AUC: 0.7133\n",
      "Epoch 4/6\n",
      "1210/1210 [==============================] - 0s 49us/sample - loss: 0.6440 - accuracy: 0.6157 - AUC: 0.6651 - val_loss: 0.6063 - val_accuracy: 0.6436 - val_AUC: 0.7190\n",
      "Epoch 5/6\n",
      "1210/1210 [==============================] - 0s 46us/sample - loss: 0.6321 - accuracy: 0.6446 - AUC: 0.6858 - val_loss: 0.6026 - val_accuracy: 0.6370 - val_AUC: 0.7234\n",
      "Epoch 6/6\n",
      "1210/1210 [==============================] - 0s 49us/sample - loss: 0.6264 - accuracy: 0.6380 - AUC: 0.6922 - val_loss: 0.5990 - val_accuracy: 0.6370 - val_AUC: 0.7258\n"
     ]
    }
   ],
   "source": [
    "# get baseline predictors for full dataset\n",
    "train, _, _ = get_baseline(df, df.index, df.index)\n",
    "\n",
    "# compile both models\n",
    "model1, model2 = compile_genre_model(\n",
    "    n_items = df.movieId.nunique(),\n",
    "    n_users = df.userId.nunique(),\n",
    "    mean_rating = df.rating.mean(), \n",
    "    n_latent=125,\n",
    "    n_hidden_1=[75,30],\n",
    "    n_hidden_2=[50,25]\n",
    ")\n",
    "\n",
    "# train rating model\n",
    "ratings = model1.fit(\n",
    "    x=[train.userId.values, train.movieId.values, train.bias.values],\n",
    "    y=train.rating.values, \n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_split=.2\n",
    ")\n",
    "\n",
    "# train genre model\n",
    "genres = model2.fit(\n",
    "    movies.movieId.values, movies.Drama.values,\n",
    "    batch_size=64, \n",
    "    epochs=7,\n",
    "    validation_split=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = movies_holdout.movieId.values\n",
    "y_test = movies_holdout.Drama.values\n",
    "y_score = pd.DataFrame(model2.predict(X_test))\n",
    "y_pred = y_score.round().astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.59      0.62        96\n",
      "           1       0.52      0.59      0.55        73\n",
      "\n",
      "    accuracy                           0.59       169\n",
      "   macro avg       0.59      0.59      0.59       169\n",
      "weighted avg       0.60      0.59      0.59       169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0  57  39\n",
       "1  30  43"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Appendix B: multi-label genre model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_genre_model(n_items, n_users, mean_rating, n_genres, n_latent, n_hidden_1, n_hidden_2, dropout_1, dropout_2):\n",
    "    \n",
    "    # item latent factors\n",
    "    item_in = Input(shape=[1])  # name='item'\n",
    "    item_em = Embedding(n_items, n_latent)(item_in)\n",
    "    item_vec = Flatten()(item_em)\n",
    "    \n",
    "    # user latent factors\n",
    "    user_in = Input(shape=[1])\n",
    "    user_em = Embedding(n_users, n_latent)(user_in)\n",
    "    user_vec = Flatten()(user_em)\n",
    "    \n",
    "    # user x item bias\n",
    "    bias = Input(shape=[1])\n",
    "    \n",
    "    # concatenate user and item vectors\n",
    "    conc = Concatenate()([item_vec, user_vec])\n",
    "    # hidden layer\n",
    "    hidden_1 = Dense(n_hidden_1)(conc)\n",
    "    leaky = LeakyReLU(alpha=0.1)(hidden_1)\n",
    "    drop_1 = Dropout(dropout_1)(leaky)\n",
    "    \n",
    "    out = Dense(1)(drop_1)\n",
    "            \n",
    "    rating = tf.math.add(Add()([out, bias]), mean_rating)\n",
    "    \n",
    "    # create model and compile it\n",
    "    model = Model([user_in, item_in, bias], rating)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # model 2\n",
    "    hidden_2 = Dense(n_hidden_2, activation='relu')(item_vec)\n",
    "    drop_2 = Dropout(dropout_2)(hidden_2)\n",
    "    genre = Dense(n_genres, activation='sigmoid')(drop_2)  # there are 18 genres\n",
    "\n",
    "    # Create model and compile it\n",
    "    model2 = Model(item_in, genre)\n",
    "    # freeze the embedding layer\n",
    "    model2.layers[1].trainable = False\n",
    "    model2.compile(optimizer='adam', loss='binary_crossentropy' , metrics=['accuracy', 'AUC'])\n",
    "    \n",
    "    return model, model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 1s 18us/sample - loss: 0.9487 - val_loss: 0.9348\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 1s 12us/sample - loss: 0.9487 - val_loss: 0.9348\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 1s 12us/sample - loss: 0.9487 - val_loss: 0.9348\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 1s 13us/sample - loss: 0.9487 - val_loss: 0.9348\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 1s 13us/sample - loss: 0.9487 - val_loss: 0.9348\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 1s 14us/sample - loss: 0.9487 - val_loss: 0.9348\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 1s 12us/sample - loss: 0.9487 - val_loss: 0.9348\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 1s 12us/sample - loss: 0.9487 - val_loss: 0.9348\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 1s 12us/sample - loss: 0.9487 - val_loss: 0.9348\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 1s 12us/sample - loss: 0.9487 - val_loss: 0.9348\n"
     ]
    }
   ],
   "source": [
    "# get baseline predictors for full dataset\n",
    "train, _, _ = get_baseline(df, df.index, df.index)\n",
    "\n",
    "# compile both models\n",
    "model1, model2 = compile_genre_model(\n",
    "    n_items = df.movieId.nunique(),\n",
    "    n_users = df.userId.nunique(),\n",
    "    mean_rating = df.rating.mean(), \n",
    "    n_genres=18,\n",
    "    n_latent=best_rating_hparams.n_factors, \n",
    "    n_hidden_1=best_rating_hparams.n_hidden,\n",
    "    n_hidden_2=64,\n",
    "    dropout_1=best_rating_hparams.dropout,\n",
    "    dropout_2=.2\n",
    ")\n",
    "\n",
    "# train rating model\n",
    "ratings = model1.fit(\n",
    "    x=[train.userId.values, train.movieId.values, train.bias.values],\n",
    "    y=train.rating.values, \n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_split=.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1345 samples, validate on 337 samples\n",
      "Epoch 1/5\n",
      "1345/1345 [==============================] - 0s 367us/sample - loss: 0.6794 - accuracy: 0.7493 - val_loss: 0.6625 - val_accuracy: 0.9054\n",
      "Epoch 2/5\n",
      "1345/1345 [==============================] - 0s 38us/sample - loss: 0.6466 - accuracy: 0.8887 - val_loss: 0.6172 - val_accuracy: 0.9228\n",
      "Epoch 3/5\n",
      "1345/1345 [==============================] - 0s 37us/sample - loss: 0.5925 - accuracy: 0.8994 - val_loss: 0.5452 - val_accuracy: 0.9232\n",
      "Epoch 4/5\n",
      "1345/1345 [==============================] - 0s 41us/sample - loss: 0.5168 - accuracy: 0.8998 - val_loss: 0.4540 - val_accuracy: 0.9232\n",
      "Epoch 5/5\n",
      "1345/1345 [==============================] - 0s 39us/sample - loss: 0.4349 - accuracy: 0.8998 - val_loss: 0.3683 - val_accuracy: 0.9232\n"
     ]
    }
   ],
   "source": [
    "# train genre model\n",
    "genres = model2.fit(\n",
    "#     movies.movieId.values, movies.Drama.values,  # drama only\n",
    "    movies.movieId.values, movies.iloc[:,-18:].values,  # multi label\n",
    "    batch_size=64, \n",
    "    epochs=5,\n",
    "    validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = movies.iloc[:,-18:]\n",
    "y_score = pd.DataFrame(model2.predict(movies.movieId.values), columns=y_true.columns)\n",
    "y_pred = y_score.round().astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "drama_true = y_true.Drama\n",
    "drama_pred = y_pred.Drama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73       957\n",
      "           1       0.00      0.00      0.00       725\n",
      "\n",
      "    accuracy                           0.57      1682\n",
      "   macro avg       0.28      0.50      0.36      1682\n",
      "weighted avg       0.32      0.57      0.41      1682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JLeslie\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\JLeslie\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\JLeslie\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(drama_true, drama_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>957</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1\n",
       "0  957  0\n",
       "1  725  0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(drama_true, drama_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.00      0.00      0.00       251\n",
      "   Adventure       0.00      0.00      0.00       135\n",
      "   Animation       0.00      0.00      0.00        42\n",
      "  Children's       0.00      0.00      0.00       122\n",
      "      Comedy       0.00      0.00      0.00       505\n",
      "       Crime       0.00      0.00      0.00       109\n",
      " Documentary       0.00      0.00      0.00        50\n",
      "       Drama       0.00      0.00      0.00       725\n",
      "     Fantasy       0.00      0.00      0.00        22\n",
      "   Film-Noir       0.00      0.00      0.00        24\n",
      "      Horror       0.00      0.00      0.00        92\n",
      "     Musical       0.00      0.00      0.00        56\n",
      "     Mystery       0.00      0.00      0.00        61\n",
      "     Romance       0.00      0.00      0.00       247\n",
      "      Sci-Fi       0.00      0.00      0.00       101\n",
      "    Thriller       0.00      0.00      0.00       251\n",
      "         War       0.00      0.00      0.00        71\n",
      "     Western       0.00      0.00      0.00        27\n",
      "\n",
      "   micro avg       0.00      0.00      0.00      2891\n",
      "   macro avg       0.00      0.00      0.00      2891\n",
      "weighted avg       0.00      0.00      0.00      2891\n",
      " samples avg       0.00      0.00      0.00      2891\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JLeslie\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\JLeslie\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\JLeslie\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\JLeslie\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\JLeslie\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\JLeslie\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=y_true.columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
