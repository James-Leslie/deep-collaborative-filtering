{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/James-Leslie/deep-collaborative-filtering/blob/master/movielens_skorch.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do:\n",
    "  - use cross validation in grid search (ML100K README explains how to use 5-fold CV for evaluation)\n",
    "  - regularize embedding layer\n",
    "  - try [this link](https://github.com/keras-team/keras/issues/9001) for making an SkLearn base estimator (look for comment by hughfdjackson)\n",
    "  - create object classes for models\n",
    "  - implement TF 2.0 data classes\n",
    "  - [paperswithcode link](https://paperswithcode.com/sota/collaborative-filtering-on-movielens-100k)\n",
    "  - [ML 100k state of the art paper](https://arxiv.org/pdf/1706.02263v2.pdf) (RMSE=0.905): details their evaluation method\n",
    "  - include genre model in grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best CV score: 0.920671 (25 : 64 : 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Add, Dense, Concatenate, Dropout, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.math import add\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'https://raw.githubusercontent.com/James-Leslie/deep-collaborative-filtering/master/data/ml-100k/'  # access from anywhere\n",
    "path = 'data/ml-100k/'  # if the files are local\n",
    "df = pd.read_csv(path+'ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       0        0       3\n",
       "1       1        1       3\n",
       "2       2        2       1\n",
       "3       3        3       2\n",
       "4       4        4       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943\n",
      "Number of items: 1682\n",
      "Min item rating: 1\n",
      "Max item rating: 5\n",
      "Mean item rating: 3.52986\n"
     ]
    }
   ],
   "source": [
    "print('Number of users:', df.userId.nunique())\n",
    "print('Number of items:', df.movieId.nunique())\n",
    "print(\"Min item rating:\", df.rating.min())\n",
    "print(\"Max item rating:\", df.rating.max())\n",
    "print(\"Mean item rating:\", df.rating.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create baseline features\n",
    "For each different train / test split, global mean and biases need to be calculated so as to avoid potential data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline(df, train_index, test_index):\n",
    "    train = df.iloc[train_index]\n",
    "    test = df.iloc[test_index]\n",
    "    \n",
    "    # compute global mean\n",
    "    global_mean = train.rating.mean()\n",
    "\n",
    "    # compute average user ratings\n",
    "    user_averages = train.groupby('userId') \\\n",
    "        .agg({'rating':'mean'}) \\\n",
    "        .rename({'rating': 'user_avg'}, axis=1) \\\n",
    "        .reset_index()\n",
    "    # add as column to train and test\n",
    "    train = pd.merge(train, user_averages, how='left', on='userId')\n",
    "    test = pd.merge(test, user_averages, how='left', on='userId').fillna(global_mean)\n",
    "\n",
    "    # compute average item ratings\n",
    "    item_averages = train.groupby('movieId') \\\n",
    "        .agg({'rating':'mean'}) \\\n",
    "        .rename({'rating': 'item_avg'}, axis=1) \\\n",
    "        .reset_index()\n",
    "    # add as column to train and test\n",
    "    train = pd.merge(train, item_averages, how='left', on='movieId')\n",
    "    test = pd.merge(test, item_averages, how='left', on='movieId').fillna(global_mean)\n",
    "\n",
    "    train['bias'] = (train['user_avg'] + train['item_avg'])/2 - global_mean\n",
    "    test['bias'] = (test['user_avg'] + test['item_avg'])/2 - global_mean\n",
    "    \n",
    "    return train, test, global_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search\n",
    "**To do**:\n",
    "  - tune dropout rates and optimiser\n",
    "  - measure impact on accuracy of genre model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(n_users, n_items, mean_rating, n_factors=25, n_hidden_1=0, n_hidden_2=0, dropout_1=.1, dropout_2=.1):\n",
    "    \n",
    "    # TODO: n_items, n_users and mean_rating are all hard coded at the moment\n",
    "    \n",
    "    # item latent factors\n",
    "    item_in = Input(shape=[1])  # name='item'\n",
    "    item_em = Embedding(n_items, n_factors)(item_in)\n",
    "    item_vec = Flatten()(item_em)\n",
    "    \n",
    "    # user latent factors\n",
    "    user_in = Input(shape=[1])\n",
    "    user_em = Embedding(n_users, n_factors)(user_in)\n",
    "    user_vec = Flatten()(user_em)\n",
    "    \n",
    "    # user x item bias\n",
    "    bias = Input(shape=[1])\n",
    "    \n",
    "    # if there is a hidden layer\n",
    "    if n_hidden_1:\n",
    "        # concatenate user and item vectors\n",
    "        conc = Concatenate()([item_vec, user_vec])\n",
    "        # hidden layer 1\n",
    "        hidden_1 = Dense(n_hidden_1)(conc)\n",
    "        leaky_1 = LeakyReLU(alpha=0.1)(hidden_1)\n",
    "        drop_1 = Dropout(dropout_1)(leaky_1)\n",
    "        \n",
    "        # if there is a second hidden layer\n",
    "        if n_hidden_2:\n",
    "            # hidden layer 2\n",
    "            hidden_2 = Dense(n_hidden_2, activation='leaky_relu')(drop_1)\n",
    "            drop_2 = Dropout(dropout_2)(hidden_2)\n",
    "            \n",
    "            # unscaled output\n",
    "            out = Dense(1)(drop_2)\n",
    "        else:\n",
    "            out = Dense(1)(drop_1)\n",
    "        \n",
    "    # if there are no hidden layers\n",
    "    else:\n",
    "        out = Dot(name=\"Dot-Product\", axes=1)([item_vec, user_vec])\n",
    "    \n",
    "    rating = add(Add()([out, bias]), mean_rating)\n",
    "    \n",
    "    # create model and compile it\n",
    "    model = Model([user_in, item_in, bias], rating)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "HP_N_FACTORS = [10, 20, 30, 50]\n",
    "HP_N_HIDDEN = [10, 20, 40, 60]\n",
    "HP_DROPOUT = [.2, .25, .3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting total of 48 models\n",
      "\n",
      "Fitting model #1 with 25: 64 architecture, 0.2 dropout rate\n",
      "CV split #1: RMSE=0.9312\n",
      "CV split #2: RMSE=0.9235\n",
      "CV split #3: RMSE=0.9181\n",
      "CV split #4: RMSE=0.9144\n",
      "CV split #5: RMSE=0.9130\n",
      "_____________________________________CV avg RMSE=0.9201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataframe to store results of grid search\n",
    "grid_results = []\n",
    "best_loss = 1\n",
    "searches = 1\n",
    "\n",
    "n_models = len(HP_N_FACTORS) * len(HP_N_HIDDEN_1) * len(HP_DROPOUT_1)\n",
    "\n",
    "print(f'Fitting total of {n_models} models\\n')\n",
    "\n",
    "for N_FACTORS in HP_N_FACTORS:\n",
    "    for N_HIDDEN in HP_N_HIDDEN:\n",
    "        for DROPOUT in HP_DROPOUT:\n",
    "            \n",
    "            print(f'Fitting model #{searches} with {N_FACTORS}: {N_HIDDEN} architecture, {DROPOUT} dropout rate')\n",
    "            searches += 1\n",
    "            \n",
    "            # CV split\n",
    "            # calculate global mean rating and bias\n",
    "            kf = KFold(n_splits=5)\n",
    "            \n",
    "            total_loss, count = 0, 1\n",
    "            min_epochs = 10\n",
    "            \n",
    "            # do CV split and compute baseline predictors\n",
    "            for train_index, test_index in kf.split(df):\n",
    "                train, test, global_mean = get_baseline(df, train_index, test_index)\n",
    "                \n",
    "                # compile model with chosen h-params\n",
    "                model = compile_model(\n",
    "                    n_users = df.userId.nunique(),\n",
    "                    n_items = df.movieId.nunique(),\n",
    "                    mean_rating = global_mean,\n",
    "                    n_factors = N_FACTORS,\n",
    "                    n_hidden_1 = N_HIDDEN,\n",
    "                    n_hidden_2 = 0,\n",
    "                    dropout_1 = DROPOUT,\n",
    "                    dropout_2 = 0\n",
    "                )\n",
    "\n",
    "                result = model.fit(x=[train.userId.values, train.movieId.values, train.bias.values],\n",
    "                                   y=train.rating.values, \n",
    "                                   batch_size=256,\n",
    "                                   epochs=10,\n",
    "                                   verbose=0,\n",
    "                                   validation_data=([test.userId.values, test.movieId.values, test.bias.values], test.rating.values))\n",
    "                \n",
    "                fold_loss = np.sqrt(np.min(result.history['val_loss']))\n",
    "                total_loss += fold_loss\n",
    "                min_epochs = min(np.argmin(result.history['val_loss']) + 1, min_epochs)\n",
    "                \n",
    "                print(f'CV split #{count}: RMSE={fold_loss:.4f}')\n",
    "                count += 1\n",
    "\n",
    "            avg_loss = total_loss / 5\n",
    "            best_loss = min(avg_loss, best_loss)\n",
    "            print(f'_____________________________________CV avg RMSE={avg_loss:.4f}')\n",
    "            \n",
    "#             plt.plot(result.history['loss'], label='train')\n",
    "#             plt.plot(result.history['val_loss'], label='val')\n",
    "#             plt.axhline(y=best_loss, color='r', lw=1, ls='-')\n",
    "#             plt.legend()\n",
    "#             plt.show()\n",
    "            \n",
    "            grid_results.append({'n_factors':N_FACTORS,\n",
    "                                 'n_hidden':N_HIDDEN,\n",
    "                                 'dropout':DROPOUT,\n",
    "                                 'val_rmse':avg_loss,\n",
    "                                 'val_epochs':min_epochs,\n",
    "                                 'train_hist':result.history['loss'],\n",
    "                                 'val_hist':result.history['val_loss']})\n",
    "            print()\n",
    "            break\n",
    "        break\n",
    "    break\n",
    "\n",
    "grid_results = pd.DataFrame(data=grid_results, columns=grid_results[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_factors</th>\n",
       "      <th>hidden_1</th>\n",
       "      <th>hidden_2</th>\n",
       "      <th>val_rmse</th>\n",
       "      <th>val_epochs</th>\n",
       "      <th>train_hist</th>\n",
       "      <th>val_hist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.920671</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.9027691205978393, 0.8514909013748169, 0.821...</td>\n",
       "      <td>[0.8927469430923461, 0.8680867597579957, 0.855...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.920688</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.899303620147705, 0.8450768502235413, 0.8144...</td>\n",
       "      <td>[0.8880050428390502, 0.8602351546287537, 0.852...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.920844</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.9057428205490112, 0.8551031059265136, 0.829...</td>\n",
       "      <td>[0.8932568130493164, 0.8695466453552246, 0.857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.920926</td>\n",
       "      <td>9</td>\n",
       "      <td>[0.9065328149795532, 0.8605140323638916, 0.838...</td>\n",
       "      <td>[0.8930669300079346, 0.8750645198822021, 0.863...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.921158</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.9001519898414612, 0.8492190532684326, 0.820...</td>\n",
       "      <td>[0.8890793560028076, 0.8680045137405396, 0.853...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.923065</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.9113345783233643, 0.8623110752105713, 0.835...</td>\n",
       "      <td>[0.9018789421081543, 0.8749676982879638, 0.860...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.923167</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.9061017292022705, 0.8587554882049561, 0.835...</td>\n",
       "      <td>[0.8932652202606202, 0.8743310714721679, 0.860...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>0.923261</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.9100314079284668, 0.8642409670829773, 0.835...</td>\n",
       "      <td>[0.8987446979522705, 0.8688390436172485, 0.856...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>0.923297</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.9099940519332885, 0.8610564653396606, 0.834...</td>\n",
       "      <td>[0.8937595949172974, 0.8704151714324951, 0.858...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.923403</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.9018851215362549, 0.8531892742156982, 0.830...</td>\n",
       "      <td>[0.8868837799072266, 0.8679521892547607, 0.860...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.923758</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.9023468208312988, 0.8539916437149048, 0.829...</td>\n",
       "      <td>[0.8903067487716675, 0.8703175521850586, 0.860...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.923859</td>\n",
       "      <td>9</td>\n",
       "      <td>[0.9221755765914917, 0.8799447551727295, 0.854...</td>\n",
       "      <td>[0.9149411571502686, 0.882751948928833, 0.8716...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.924110</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.9127919805526733, 0.8627981325149536, 0.835...</td>\n",
       "      <td>[0.9015868776321411, 0.8756962329864502, 0.863...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>0.924187</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.911981563949585, 0.8676641355514526, 0.8435...</td>\n",
       "      <td>[0.9022162155151368, 0.8766730876922607, 0.862...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0.924382</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.9068941417694092, 0.8604565494537354, 0.834...</td>\n",
       "      <td>[0.8945454156875611, 0.8716715154647827, 0.860...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.924388</td>\n",
       "      <td>9</td>\n",
       "      <td>[0.9100102945327759, 0.862985676574707, 0.8398...</td>\n",
       "      <td>[0.8967712184906006, 0.8751086503982544, 0.863...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>0.924663</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.9054953651428223, 0.8560425718307495, 0.830...</td>\n",
       "      <td>[0.8938167184829712, 0.869254372215271, 0.8637...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.924717</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.9084684480667115, 0.860950048828125, 0.8353...</td>\n",
       "      <td>[0.8963210441589355, 0.8729684455871582, 0.864...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>0.924911</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.9089969463348389, 0.8599115159988403, 0.834...</td>\n",
       "      <td>[0.8929353338241577, 0.8727057006835938, 0.861...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.925057</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.9056135330200196, 0.8557875400543213, 0.827...</td>\n",
       "      <td>[0.8912595794677735, 0.8732660816192627, 0.856...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_factors  hidden_1  hidden_2  val_rmse  val_epochs  \\\n",
       "18         25        64         0  0.920671           6   \n",
       "29         50        64         0  0.920688           5   \n",
       "7          10        64         0  0.920844           8   \n",
       "3          10        32         0  0.920926           9   \n",
       "25         50        32         0  0.921158           5   \n",
       "26         50        32         8  0.923065           6   \n",
       "11         25        16         0  0.923167           7   \n",
       "19         25        64         8  0.923261           6   \n",
       "9          10        64        16  0.923297           7   \n",
       "22         50        16         0  0.923403           8   \n",
       "14         25        32         0  0.923758           6   \n",
       "4          10        32         8  0.923859           9   \n",
       "6          10        32        32  0.924110           7   \n",
       "8          10        64         8  0.924187           7   \n",
       "10         10        64        32  0.924382           5   \n",
       "0          10        16         0  0.924388           9   \n",
       "31         50        64        16  0.924663           5   \n",
       "24         50        16        16  0.924717           7   \n",
       "16         25        32        16  0.924911           6   \n",
       "28         50        32        32  0.925057           5   \n",
       "\n",
       "                                           train_hist  \\\n",
       "18  [0.9027691205978393, 0.8514909013748169, 0.821...   \n",
       "29  [0.899303620147705, 0.8450768502235413, 0.8144...   \n",
       "7   [0.9057428205490112, 0.8551031059265136, 0.829...   \n",
       "3   [0.9065328149795532, 0.8605140323638916, 0.838...   \n",
       "25  [0.9001519898414612, 0.8492190532684326, 0.820...   \n",
       "26  [0.9113345783233643, 0.8623110752105713, 0.835...   \n",
       "11  [0.9061017292022705, 0.8587554882049561, 0.835...   \n",
       "19  [0.9100314079284668, 0.8642409670829773, 0.835...   \n",
       "9   [0.9099940519332885, 0.8610564653396606, 0.834...   \n",
       "22  [0.9018851215362549, 0.8531892742156982, 0.830...   \n",
       "14  [0.9023468208312988, 0.8539916437149048, 0.829...   \n",
       "4   [0.9221755765914917, 0.8799447551727295, 0.854...   \n",
       "6   [0.9127919805526733, 0.8627981325149536, 0.835...   \n",
       "8   [0.911981563949585, 0.8676641355514526, 0.8435...   \n",
       "10  [0.9068941417694092, 0.8604565494537354, 0.834...   \n",
       "0   [0.9100102945327759, 0.862985676574707, 0.8398...   \n",
       "31  [0.9054953651428223, 0.8560425718307495, 0.830...   \n",
       "24  [0.9084684480667115, 0.860950048828125, 0.8353...   \n",
       "16  [0.9089969463348389, 0.8599115159988403, 0.834...   \n",
       "28  [0.9056135330200196, 0.8557875400543213, 0.827...   \n",
       "\n",
       "                                             val_hist  \n",
       "18  [0.8927469430923461, 0.8680867597579957, 0.855...  \n",
       "29  [0.8880050428390502, 0.8602351546287537, 0.852...  \n",
       "7   [0.8932568130493164, 0.8695466453552246, 0.857...  \n",
       "3   [0.8930669300079346, 0.8750645198822021, 0.863...  \n",
       "25  [0.8890793560028076, 0.8680045137405396, 0.853...  \n",
       "26  [0.9018789421081543, 0.8749676982879638, 0.860...  \n",
       "11  [0.8932652202606202, 0.8743310714721679, 0.860...  \n",
       "19  [0.8987446979522705, 0.8688390436172485, 0.856...  \n",
       "9   [0.8937595949172974, 0.8704151714324951, 0.858...  \n",
       "22  [0.8868837799072266, 0.8679521892547607, 0.860...  \n",
       "14  [0.8903067487716675, 0.8703175521850586, 0.860...  \n",
       "4   [0.9149411571502686, 0.882751948928833, 0.8716...  \n",
       "6   [0.9015868776321411, 0.8756962329864502, 0.863...  \n",
       "8   [0.9022162155151368, 0.8766730876922607, 0.862...  \n",
       "10  [0.8945454156875611, 0.8716715154647827, 0.860...  \n",
       "0   [0.8967712184906006, 0.8751086503982544, 0.863...  \n",
       "31  [0.8938167184829712, 0.869254372215271, 0.8637...  \n",
       "24  [0.8963210441589355, 0.8729684455871582, 0.864...  \n",
       "16  [0.8929353338241577, 0.8727057006835938, 0.861...  \n",
       "28  [0.8912595794677735, 0.8732660816192627, 0.856...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results.sort_values('val_rmse').head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
